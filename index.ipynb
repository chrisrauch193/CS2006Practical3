{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS2006 Practical 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook provides an analysis of a data sample taken from the 2011 UK census containing 569,741 individuals.  Each individual in the dataset has 18 properties, which include age, sex, religion and economic activity.\n",
    "\n",
    "The dataset and related information are available at www.ons.gov.uk/census/2011census.\n",
    "\n",
    "The analysis has been conducted in Python, primarily making use of the data processing library `pandas` and plotting library `matplotlib`.  These libraries have been used to provide a descriptive and graphical analysis of important trends and features of the dataset.\n",
    "\n",
    "The following requirements have been implemented:\n",
    "\n",
    "Basic Requirements:\n",
    "\n",
    "1. Refine the dataset, checking for inconsistencies.\n",
    "2. Descriptive analysis of parts of the dataset.\n",
    "3. Frequency plots and pie charts to reveal interesting trends.\n",
    "\n",
    "Additional Requirements:\n",
    "\n",
    "1. (Easy) Produce two-way frequency tables of specific pairs of variables.\n",
    "2. (Easy) Perform queries on the dataset to extract relevant information.\n",
    "3. (Medium) Represent the tables from 1. as 3D plots.\n",
    "4. (Medium) Use ipywidgets to construct interactive plots that change based on a user-defined selection.\n",
    "5. (Hard) Use a map to interpret and show data.\n",
    "6. (Hard) Conduct an analysis on another large dataset.\n",
    "7. (Hard) Use Binder (www.mybinder.com) to provide a complete environment for reproducing the analysis.\n",
    "\n",
    "The following import statements are required for the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Force plots to appear within Jupyter notebook.\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Data processing libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.Series.__unicode__ = pd.Series.to_string\n",
    "\n",
    "# Plotting libraries.\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ipywidgets functionality.\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipykernel.pylab.backend_inline import flush_figures\n",
    "\n",
    "# User defined utilities.\n",
    "import src.utils as utils\n",
    "import src.refine as refine\n",
    "import src.descriptive as descriptive\n",
    "import src.plotting as plotting\n",
    "import src.plotting_3D as plotting_3D\n",
    "import src.cricket as cricket\n",
    "\n",
    "# Check for the presence of mapping capabilities.\n",
    "mapping_installed = True\n",
    "try:\n",
    "    import src.mapping as mapping\n",
    "except ImportError:\n",
    "    mapping_installed = False\n",
    "\n",
    "# Built-in utilities.\n",
    "import copy\n",
    "import inspect\n",
    "\n",
    "# Set the style for all forthcoming plots.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Requirements\n",
    "### 1. Dataset refinement\n",
    "The dataset was read using a `pandas` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/census2011.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was then refined using a series of functions that checked for missing values, values that were outside their specified ranges, and duplicate values.  This code is contained in the module `refine.py`, which is reproduced below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(inspect.getsource(refine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refining the dataset in this way produced an almost identical dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = refine.refine_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All codes in the dataset were then translated ino their corresponding values, as defined by the census parameters.  This translation step was conducted early in the analysis to ensure that future output was easily readable.  It must be noted that this choice represents a tradeoff between convenience and speed/memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_translated = utils.translate(df)\n",
    "df_translated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Descriptive analysis\n",
    "\n",
    "A descriptive analysis of the dataset was then conducted using a number of modular functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(inspect.getsource(descriptive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive analyses found the number of records in the dataset, the data types of each variable, and the number of observations of each unqiue value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(descriptive.total_records(df_translated) + \"\\n\")\n",
    "print(descriptive.all_data_types(df_translated) + \"\\n\")\n",
    "print(descriptive.count_occurrences(df_translated, [\"Person ID\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting frequency counts and pie charts of a single variable, modular functions were written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(inspect.getsource(plotting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the sample data, the South East of England and London have the highest populations (shown in the plot below).  Wales and the North East of England have the smallest populations in the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plotting.plot_bar_group_count(\n",
    "    df_translated,\n",
    "    'Region',\n",
    "    'Frequencies of Resident Regions in 2011 Census Sample',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest employment group corresponds to the one with no code required, meaning that the largest group of people is the one containing those under 16, those who have never worked, and students or schoolchildren living away during the term-time.  Within the rest of the data, The largest groups are elementary occupations or professional groups.  The smallest group is the process, plant, and machine operatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plotting.plot_bar_group_count(\n",
    "    df_translated,\n",
    "    'Occupation',\n",
    "    'Frequencies of Resident Occupations in 2011 Census Sample',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to age, the largest group is the one containing children under the age of 15.  The smallest group contains those people over the age of 75.  An interesting point to note is that for groups within the bounds of 16 and 64 years, the frequency counts are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plotting.plot_pie_group_count(\n",
    "    df_translated,\n",
    "    'Age',\n",
    "    'Proportions of Resident Ages in 2011 Census Sample',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the proportions of the sample by their economic activity, the largest group is the group of people by far is those who are employed.  The second largest group is the group for which there is no code, which means that they are children under the age of 16, full time students, or schoolchildren who live elsewhere during term-time.  There is also a large group of those who are retired, which captures the nature of the aging population in the UK.  Aside from these observations, the group sizes are fairly similar -- and range from around 2% of the total to 7% of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plotting.plot_pie_group_count(\n",
    "    df_translated,\n",
    "    'Economic Activity',\n",
    "    'Proportions of Resident Economic Activity in 2011 Census Sample',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Requirements\n",
    "### 1. Two-way frequency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For producing the following two-way frequency tables, the `pandas` function `crosstab` was used.\n",
    "\n",
    "For all industries aside from agriculture, London has a far higher number of the working population than the rest of the regions -- especially the North East of England, which has a significantly lower number of people working in all industries than the rest of the country.  In addition, agriculture is the industry with the fewest workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df_translated['Region'], df_translated['Industry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining a two-way frequency table of approximated social grade and occuption, by far the most frequent combination is where no code is required for either.  As the social grades change, the most frequent occupation in that group also changes.  For example: in the social group AB (the highest social code) the largest numbers of people are employed in managerial/professional occupations (generally high paying jobs), whereas in the social code DE (the lowest social code) the highest numbers of people seen to be employed in elementary/process operatives occupations (which tends to be lower paid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df_translated['Occupation'], df_translated['Approximated Social Grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset queries\n",
    "\n",
    "This requirement revolved around filtering through data and returning insightful information.\n",
    "\n",
    "Analysing the number of economically active people by region, we find that that the largest number of people live in the South East and London.  These locations both have the highest populations, and so this is the expected effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to only contain economically active individuals.\n",
    "economic_activity = df[df[\"Economic Activity\"].isin(range(1, 5))]\n",
    "economic_activity = utils.translate(economic_activity)\n",
    "\n",
    "pd.crosstab(index=economic_activity['Region'], columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plotting.plot_bar_group_count(\n",
    "    economic_activity,\n",
    "    'Region',\n",
    "    'Frequencies of Economically Active Resident Regions in 2011 Census Sample',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the number of economically active people by age, the largest groups are those within the range of 25 to 64.  This is as would be expected, due to the largest total number of people being in those categories.  Furthermore, the number of economically people over the age of 65 is significantly lower -- again, as would be expected due to the proportion of these people who are retired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(index=economic_activity['Age'], columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plotting.plot_bar_group_count(\n",
    "    economic_activity,\n",
    "    'Age',\n",
    "    'Frequencies of Economically Active Resident Ages in 2011 Census Sample',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next piece of analysis checks whether there are any discrepancies between the student status of an individual and their economic activity.  It would be illegal for a student to be anything other than an economically active (code 4) or economically inactive (code 6) student.  The analysis confirms that there are no conflicts, by filtering the dataset based on this query and checking the length of the resulting list of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_discrepancies_query_filter(df, variable_a, values_a, variable_b, values_b):\n",
    "    \"\"\"Return records where two specified variables are in two specified sets.\"\"\"\n",
    "\n",
    "    return df[(df[variable_a].isin(values_a)) & (df[variable_b].isin(values_b))]\n",
    "\n",
    "num_conflicting = len(digit_discrepancies_query_filter(df, \"Student\", [1], \"Economic Activity\", [1, 2, 3, 5, 7, 8, 9]))\n",
    "print(\"There are \" + str(num_conflicting) + \" conflicting records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional analysis was conducted to calculate statistics relating to the hours worked by students.  The following analysis finds the average number of hours per week worked by all students, and the average number of hours worked by economically active students only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hours_categories(df):\n",
    "    \"\"\"Return a list of counts for the number of records in each working hours category.\"\"\"\n",
    "\n",
    "    codes = range(1, 5)\n",
    "\n",
    "    return list(map(lambda i: len((df[df[\"Hours worked per week\"] == i])), codes))\n",
    "\n",
    "\n",
    "def elemwise_product(a, b):\n",
    "    \"\"\"Return the elementwise product of two arrays.\"\"\"\n",
    "    \n",
    "    def product(t):\n",
    "        x, y = t\n",
    "        return x * y\n",
    "    \n",
    "    return sum(map(product, zip(a, b)))\n",
    "\n",
    "\n",
    "# Extract dataframes for different classes of students.\n",
    "df_students = df[df[\"Student\"] == 1]\n",
    "df_full_students = digit_discrepancies_query_filter(df_students, \"Student\", [1], \"Economic Activity\", [4])\n",
    "\n",
    "# Retrieve the number of hours worked in each category by both datasets.\n",
    "categories_students = hours_categories(df_students)\n",
    "categories_full_students = hours_categories(df_full_students)\n",
    "\n",
    "# Define the centre point of the hours categories.\n",
    "num_hours_list = [7.5, 23, 39.5, 56.5]\n",
    "\n",
    "# Calculate the total number of hours worked per student per week.\n",
    "hours_students = elemwise_product(num_hours_list, categories_students) / len(df_students)\n",
    "hours_full_students = elemwise_product(num_hours_list, categories_full_students) / len(df_full_students)\n",
    "\n",
    "print(\"%.2f\" % hours_students + \" hours worked per week on average by all students.\")\n",
    "print(\"%.2f\" % hours_full_students + \" hours worked per week on average by economically active students.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 3D plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of analysis was conducted to represent the tables in additional requirement 1 as three dimensional plots.  The code used for this purpose is provided below.  The raw dataset (with codes instead of translated data values) was used to reduce clutter on the plot and make the labels easily visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(plotting_3D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we show a plot for the direct frequency comparison of region and industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plotting_3D.plot_3d_table_count(\n",
    "        df,\n",
    "        'Region',\n",
    "        'Industry',\n",
    "        'Frequencies Residents by Region and Industry in 2011 Census',\n",
    "        'Region',\n",
    "        'Industry',\n",
    "        rotation=(30, 130)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plotting_3D.plot_3d_table_count(\n",
    "        df,\n",
    "        'Occupation',\n",
    "        'Approximated Social Grade',\n",
    "        'Frequencies Residents by Occupation and Social Grade in 2011 Census',\n",
    "        'Occupation',\n",
    "        'Social Grade',\n",
    "        rotation=(30, 130)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section required the use of ipywidgets to analyse the number of people working in industry for different regions and ages.  Both age range and industry are listed in the drop down boxes below, and their selection will update the plot shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def industry_func(region, age):\n",
    "    \"\"\"Plot a frequency bar chart broken down by region, for a given age group.\"\"\"\n",
    "    \n",
    "    # Filter the data.\n",
    "    filtered = df_translated[(df_translated['Region'] == region) & (df_translated['Age'] == age)]\n",
    "    \n",
    "    # Plot.\n",
    "    name = \"Industry count of ages \" + age +\" in \" + region\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plotting.plot_bar_group_count(\n",
    "        filtered, \n",
    "        'Industry', \n",
    "        name,\n",
    "        wrap_chars = 20\n",
    "    )\n",
    "    \n",
    "    # Flush existing figures to avoid build up.\n",
    "    flush_figures()\n",
    "\n",
    "# Set up the ipywidget.\n",
    "region_values = df_translated.Region.unique().tolist()\n",
    "age_values = df_translated.Age.unique().tolist()\n",
    "interact(industry_func, region=region_values, age=age_values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plotting data on a map\n",
    "\n",
    "This extension required data relating to different regions to be displayed on a map.  The `matplotlib` extension library named `basemap` was used for this purpose.\n",
    "\n",
    "`basemap` provides standard functionality that allows maps to be drawn with features that include coastlines and country borders.  For producing choropleth maps that communicate information about individual regions, shapefiles had to be used.  These are files that represent polygons (corresponding to some geographic body of interest) as a series of points with latitudes and longitudes, which can be manipulated according to values contained in specified datasets.\n",
    "\n",
    "For this investigation, shapefiles of the government office regions (GORs) for English census regions were obtained from datashare.is.ed.ac.uk/handle/10283/2404.  Unfortunately, this dataset did not include Wales -- so the analysis was focused only on regions in England.\n",
    "\n",
    "The following function was written to plot the populations of each region on a map of England:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mapping_installed:\n",
    "    print(inspect.getsource(mapping))\n",
    "else:\n",
    "    print(\"Mapping capabilities are not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map was then generated by running the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mapping_installed:\n",
    "    mapping.plot_population_map(df_translated, \"../data/regions\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Mapping capabilities are not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analysis of alternate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset chosen to analyse as an extension contained all balls bowled in the group stages of the 2016 Indian Premier League T20 cricket league.  The data was obtained from cricsheet.org/downloads/ipl.zip.  All .csv files not from the group stages were filtered out, and then the remaining files were read into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IPLData = cricket.get_data(\"./data/cricket_data\")\n",
    "IPLData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analysing each stadium, the data had to be processed to account of the fact that different numbers of matches were played at each.  To make the comparisons fair, all values were normalised to be per match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games_at_venue = IPLData.drop_duplicates('Match Number')['Venue'].value_counts()\n",
    "num_games_at_venue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most common numbers of runs scored off any given ball were dot balls and 1s -- which is logical, as they are the type of runs which are easiest to score for the batting team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_no_games(row):\n",
    "    \"\"\"Act on crosstab row to normalise the number of runs scored per ball per game.\"\"\"\n",
    "    \n",
    "    # Normalise the row.\n",
    "    venue_count = num_games_at_venue.index == row.name\n",
    "    venue_count = num_games_at_venue[list(venue_count).index(True)]\n",
    "    normalised = row / venue_count\n",
    "    \n",
    "    return normalised.astype(int)\n",
    "\n",
    "# Create crosstab to give frequencies of runs scored per ball.\n",
    "total_runs = IPLData['Runs'] + IPLData['Extras']\n",
    "total_runs = total_runs.rename('No. Of Runs on Ball')\n",
    "total_runs_stadium = pd.crosstab(IPLData['Venue'], total_runs)\n",
    "\n",
    "# Remove single outlier.\n",
    "del total_runs_stadium[7]\n",
    "\n",
    "# Normalise rows and display.\n",
    "total_runs_stadium = total_runs_stadium.apply(get_no_games, axis=1)\n",
    "total_runs_stadium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the data, the ground at which there was the most number of sixes was the M Chinnaswamy stadium, a ground which has a reputation for being one of the highest scoring grounds in the country.  The first plot powered by ipywidgets allows the venue to be altered and the distribution of runs scored per ball to be observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stadium_runs_func(venue):\n",
    "    \"\"\"Return a plot of the number of runs scored per ball, filtered by venue.\"\"\"\n",
    "    \n",
    "    # Get filtered data.\n",
    "    filtered = pd.DataFrame(total_runs_stadium.loc[venue])\n",
    "    \n",
    "    # Create axes and return.\n",
    "    axes = filtered.plot(kind=\"barh\", legend=False, figsize=(10, 10),\n",
    "                         title=\"Average times runs were made per game at\\n\" + venue)\n",
    "    axes.set_xlabel(\"Average number of occurrences per game\")\n",
    "    axes.set_ylabel(\"Runs per ball\")\n",
    "    flush_figures()\n",
    "\n",
    "venues = list(total_runs_stadium.index)\n",
    "interact(stadium_runs_func, venue=venues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second plot powered by ipywidgets inverts the selections, so the number of runs per ball can be cycled through to observe the differences between stadiums.  Again, the M Chinnaswamy stadium is revealed to be conmfortably the highest scoring ground -- in particular, with the number of sixes hit there dwarfing all other grounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runs_ball_func(runs_per_ball):\n",
    "    \"\"\"Return a plot of the number of observations at each venue, filtered by number of runs scored per ball.\"\"\"\n",
    "    \n",
    "    filtered = total_runs_stadium[int(runs_per_ball)]\n",
    "    axes = filtered.plot(kind=\"barh\", figsize=(10, 10),\n",
    "                         title=\"Average times \" + str(runs_per_ball) + \" runs per ball were made\")\n",
    "    axes.set_xlabel(\"Average number of occurrences per game\")\n",
    "    axes.set_ylabel(\"Venue\")\n",
    "    flush_figures()\n",
    "    \n",
    "runs = list(total_runs_stadium.columns.values)\n",
    "interact(runs_ball_func, runs_per_ball=runs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the number of runs scored per ball across different over numbers, it can be seen that the frequency of boundaries increases as the over gets closer to the end of the game.  Furthermore -- in the middle overs (between overs 7 and 15), the number of 1s and 2s increases significantly as the batsmen look to try and rotate strike.  In the powerplay (the first 6 overs), there is an increased number of dots (0s) and boundaries (4s and 6s) when compared with the middle overs as the batsmen look to try and score when the fielding restrictions are in place.\n",
    "\n",
    "The following crosstabs show this effect for the first 10 balls and last 10 balls of an innings.  In particular, the number of 0s is significantly higher at the start of the innings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_runs_by_ball = pd.crosstab(IPLData['Ball No.'], total_runs)\n",
    "num_runs_by_ball.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs_by_ball.tail(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the same effect, but with the option of using a slider ipywidget to change the over being analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def over_num_func(over_number):\n",
    "    \"\"\"Return a plot of the number of runs scored per ball, filtered by over number.\"\"\"\n",
    "    \n",
    "    # Retrive the relevant data.\n",
    "    filtered = num_runs_by_ball[np.ceil(num_runs_by_ball.index) == over_number]\n",
    "    \n",
    "    # Remove outlier.\n",
    "    del filtered[7]\n",
    "    \n",
    "    # Create axes and plot.\n",
    "    axes = filtered.plot(kind=\"barh\", figsize=(12, 12), title=\"Count of Run Type for each Ball in Over Number \"+ str(over_number))\n",
    "    axes.set_xlabel(\"Totals\")\n",
    "    axes.set_ylabel(\"Balls in over \" + str(over_number))\n",
    "    axes.legend([\"Dot Ball\", \"One Run\", \"Two Runs\", \"Three Runs\", \"Four Runs\", \"Five Runs\", \"Six Runs\"], loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    flush_figures()\n",
    "    \n",
    "interact(over_num_func, over_number=(1, 20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of runs per innings, there are significantly more scored in the first innings overall.  This is as expected, given the fact that it is only possible for the team batting second to score a limited number of runs more than the team batting first (i.e. the game is over when the chasing team accumulates more runs than the team batting first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get runs per innings.\n",
    "innings_runs = IPLData.groupby(['Innings'])['Runs'].sum()\n",
    "innings_runs = pd.Series.to_frame(innings_runs)\n",
    "\n",
    "# Plot runs per innings.\n",
    "innings_runs_plot = innings_runs.plot(kind=\"barh\", legend=False, figsize=(10, 5), title=\"Total Runs per Innings\")\n",
    "innings_runs_plot.set_xlabel(\"Runs\")\n",
    "innings_runs_plot.set_ylabel(\"Innings Number\")\n",
    "innings_runs_plot;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing extras conceded by innings, it becomes apparent that there are far more extras in the second innings than the first.  This makes sense, as there is generally far more pressure on the bowling team in the second innings -- which would lead to more mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get extras per innings.\n",
    "innings_extras = IPLData.groupby(['Innings'])['Extras'].sum()\n",
    "innings_extras = pd.Series.to_frame(innings_extras)\n",
    "\n",
    "# Plot extras per innings.\n",
    "innings_extras_plot = innings_extras.plot(kind=\"barh\", legend=False, figsize=(10, 5), title=\"Total Extras per Innings\")\n",
    "innings_extras_plot.set_xlabel(\"Extras\")\n",
    "innings_extras_plot.set_ylabel(\"Innings Number\")\n",
    "innings_extras_plot;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the types of the runs which were scored by each team revealed some interesting observations.  For each team, the most common number of runs scored on any ball were 0s and 1s.  This aligns with what would be expected -- the difficulty of scorign runs increases as the number of runs increases, so more runs are scored with lower frequency in general.\n",
    "\n",
    "Interestingly, very few 3s were scored -- which may have been due to the fact that stadiums in India are quite small in general, and the ground is not big enough to allow the batsmen to run 3 runs.\n",
    "\n",
    "The majority of teams scored similar amounts of each number of run.  However, there are certain anomalies -- for example, Mumbai and Kolkata scored significantly less 2s than the other teams and RCB scored more 4s and 6s than any other team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Type of Runs by Teams\n",
    "team_runs = IPLData['Runs'] + IPLData['Extras']\n",
    "team_runs = team_runs.rename('Count of Run Type')\n",
    "team_run_types = pd.crosstab(IPLData['Batting Team'], team_runs)\n",
    "team_run_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table presents those bowlers who took the most wickest in the competition.  It can be seen that both RCB and Sunrisers Hyderabad have two entries in the top five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getBowlingTeam(row):\n",
    "    \n",
    "    record = allBowlers[allBowlers['Bowler'] == row.name]\n",
    "    temp = record['Bowling Team']\n",
    "    temp = temp.values \n",
    "    \n",
    "    return temp\n",
    "\n",
    "allBowlers = IPLData.drop_duplicates(subset = 'Bowler')\n",
    "bowlerswickets = IPLData[((IPLData['How Out'] != '-') & (IPLData['How Out'] != 'run out'))]\n",
    "allwickets = bowlerswickets['Bowler'].value_counts()\n",
    "allwickets = pd.Series.to_frame(allwickets)\n",
    "allwickets.insert(1,'Team',None)\n",
    "allwickets = allwickets.sort_values('Bowler',ascending = 0)\n",
    "allwickets['Team'] = allwickets.apply(getBowlingTeam, axis=1)\n",
    "allwickets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the same information but reveals how, interestingly, the best performing bowlers (with more than 15 wickets) are more sparesly represented than those bowlers with 15 and fewer wickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Top10WicketTakersGraph = allwickets.ix[:10].plot(kind = \"Barh\",figsize=(10,6),sort_columns = True,title =(\"Highest Wicket Takers\"),legend = False)\n",
    "Top10WicketTakersGraph.set_xlabel(\"Number of Wickets Taken\")\n",
    "Top10WicketTakersGraph.set_ylabel(\"Bowler Name\")\n",
    "Top10WicketTakersGraph;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the dataset split accordign to each team, we find a surprising trend.  For the teams who took the most wickets, these wickets were spread amongst many bowlers -- whereas in teams which did not take as many wickets, the large proportion of those wickets were shared out between 1 or 2 players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bowlingfunc(Team):\n",
    "    \n",
    "    teamNameWickets = bowlerswickets[bowlerswickets['Bowling Team'] == Team]\n",
    "    name = \"Total Wickets in \" + Team\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plotting.plot_bar_group_count(\n",
    "        teamNameWickets, \n",
    "        'Bowler', \n",
    "        name,\n",
    "        wrap_chars = 20\n",
    "    )\n",
    "    flush_figures()\n",
    "    \n",
    "wickets = allwickets.Team.unique()\n",
    "wickets = wickets.tolist()\n",
    "\n",
    "interact(bowlingfunc, Team=wickets);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 run scorers for the IPL in 2016 were mainly in three categories.  The top player was Virat Kohli (an RCB player), who had an excellent IPL season and scored far more runs than any other player.  He was followed by 2 players who also had good seasons: AB de Villiers and David Warner.  There is a significant gap between these three players and the remainder of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find the top run scorers.\n",
    "allBatsmen = IPLData.drop_duplicates(subset='Striker')\n",
    "\n",
    "def getBattingTeam(row):\n",
    "    record = allBatsmen[allBatsmen['Striker'] == row.name]\n",
    "    teamName = record['Batting Team']\n",
    "    teamName = teamName.values \n",
    "    return teamName\n",
    "\n",
    "allBatsmen = IPLData.drop_duplicates(subset = 'Striker')\n",
    "allruns = IPLData.groupby(['Striker'])['Runs'].sum()\n",
    "allruns = pd.Series.to_frame(allruns)\n",
    "allruns = allruns\n",
    "allruns.insert(1,'Team',None)\n",
    "allruns = allruns.sort_values('Runs',ascending =0)\n",
    "allruns['Team'] = allruns.apply(getBattingTeam, axis=1)\n",
    "allruns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot displays the same data, and shows the large gap between the top three scorers and the remainder of the batsmen in the IPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Top10RunScorersGraph = allruns.ix[:10].plot(kind=\"barh\", figsize=(10, 6), sort_columns=True,\n",
    "                                            title=\"Highest Run Scorers\", legend = False)\n",
    "Top10RunScorersGraph.set_xlabel(\"Number of Runs Scored\")\n",
    "Top10RunScorersGraph.set_ylabel(\"Bastmen Name\")\n",
    "Top10RunScorersGraph;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing run scoring per team shows a few interesting trends.  In teams such as Royal Challangers Bangalore and the Sunrisers Hyderabad, multiple batsmen scored many more runs than any other people in the team.  In other teams (which did not make the playoffs), only a single batsmen scored the majority of the runs -- for example the Rising Pune Supergiants and the Mumbai Indians.  This suggests that to make more runs and win more games, a number of batsmen need to score many runs for the team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runscorers(Team):\n",
    "    teamNameRuns = allruns[allruns['Team'] == Team]\n",
    "    teamRunsGraph = teamNameRuns.plot(kind = \"Barh\",figsize=(7,7),sort_columns = True,title =(\"Highest Run Scorers for \" + Team),legend = False)\n",
    "    teamRunsGraph.set_xlabel(\"Number of Runs Scored\")\n",
    "    teamRunsGraph.set_ylabel(\"Bastmen Name\")\n",
    "    flush_figures()\n",
    "    \n",
    "runs = allruns.Team.unique()\n",
    "runs = runs.tolist()\n",
    "\n",
    "interact(runscorers, Team=runs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of runs each team scored, we find that the RCB scored significantly more runs than all of the other teams.  This could have been due to the fact that they played all of their home games at the M Chinnaswamy stadium (a significantly smaller ground than others used in the IPL) -- in addition to the RCB having 2 of the best batsmen playing for them.  All of the other teams are relatively closer together in terms of runs, which further exaggerates the number of runs which RCB made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total Team Runs\n",
    "teamruns = IPLData.groupby(['Batting Team'])['Runs'].sum()\n",
    "teamruns = pd.Series.to_frame(teamruns)\n",
    "teamruns = teamruns.sort_values('Runs',ascending = 0)\n",
    "teamruns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the same data, but emphasises just how dominant RCB were in terms of run scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "teamRunsGraph = teamruns.plot(kind = \"barh\",legend = False,title = \"Total Number of Runs by Team\",figsize=(7,4))\n",
    "teamRunsGraph.set_xlabel(\"Number of Runs\")\n",
    "teamRunsGraph.set_ylabel(\"Team\")\n",
    "teamRunsGraph;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team which had the most extras was the Kolkata Knight Riders, and the other teams were all relatively even -- aside from RCB and Kings XI Punjab, who had the lowest number of extras throughout the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total Team Extras\n",
    "teamextras = IPLData.groupby(['Batting Team'])['Extras'].sum()\n",
    "teamextras = pd.Series.to_frame(teamextras)\n",
    "teamextras = teamextras.sort_values('Extras',ascending = 0)\n",
    "teamextras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kolkata Knight Riders took the most wickets throughout the season.  They were followed by RCB, and both teams made the playoffs.  The teams which took the least number of wickets were Mumbai Indians and the Gujarat Lions, although surprisingly the Gujarat Lions were the team which had the highest number of wins.  This shows that they were extremely reliant on their batting to win their games -- something which was furthered by the fact that they only won 1 game batting first, meaning that their bowling lineup was unable to take wickets and win games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total Team Wickets\n",
    "teamwickets = IPLData[((IPLData['How Out'] != '-'))]\n",
    "teamwickets = teamwickets['Bowling Team'].value_counts()\n",
    "teamwickets = pd.Series.to_frame(teamwickets)\n",
    "teamwickets = teamwickets.sort_values('Bowling Team',ascending = 0)\n",
    "teamwickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the total number of wins by team, the 4 teams which were in the playoff stages were the 4 teams with the most wins in the group stages.  The eventual winners, however, were not the Gujrat Lions but rather the Sunrisers Hydrabad -- which highlights the unpredictability of the playoff stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#number of wins per team \n",
    "allwins = IPLData.drop_duplicates(subset = 'Match Number')\n",
    "teamwins = allwins['Winner'].value_counts()\n",
    "teamwins = teamwins.rename('Wins')\n",
    "teamwins = pd.Series.to_frame(teamwins)\n",
    "teamwins = teamwins.rename(columns = {'Batting Team':'Wins'})\n",
    "teamwins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the wins batting first or batting second, all teams apart from the RCB have a higher win ratio batting second.  This is most likely due to the fact that their players were less comfortable chasing a concrete target and dealing with the mental pressure it can stimulate.  Some teams had a significant difference in the number of wins batting first or second -- for example the Gujarat Lions (who won almost exclusively while batting second). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Wins By Batting First or second \n",
    "allwins = IPLData.drop_duplicates(subset = 'Match Number')\n",
    "winsBatting = allwins[(allwins['Innings'] == 1 & (allwins['Winner'] == allwins['Batting Team'])) | (allwins['Innings'] == 2 & (allwins['Winner'] == allwins['Bowling Team']))]\n",
    "winsBatting = winsBatting['Winner'].value_counts()\n",
    "winsBatting = pd.Series.to_frame(winsBatting)\n",
    "winsBatting['Won Batting Second'] = allwins['Winner'][(allwins['Innings'] == 1 & (allwins['Winner'] == allwins['Bowling Team'])) | (allwins['Innings'] == 2 & (allwins['Winner'] == allwins['Batting Team']))].value_counts()\n",
    "winsBatting = winsBatting.rename(columns = {'Winner':'Won Batting First'})\n",
    "winsBatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "winsBattingGraph = winsBatting.plot(kind = \"Barh\",legend = False,figsize=(10,8), title = \"Number of wins by Batting First Vs Batting Second\")\n",
    "winsBattingGraph.set_xlabel(\"Number of Wins\")\n",
    "winsBattingGraph.set_ylabel(\"Team\")\n",
    "winsBattingGraph.legend([\"Batting First Wins\",\"Batting Second Wins\"],loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "winsBattingGraph;"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "3867e1007a064b309384d0aa38ae28f8": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "ea7fe070e7a74f30be9a01450e4bc014": {
     "views": [
      {
       "cell_index": 58
      }
     ]
    },
    "f9336774a5954468a78200baf3454f16": {
     "views": [
      {
       "cell_index": 45
      }
     ]
    },
    "fa4a81a68c4f426fb2b9cf7b210918d3": {
     "views": [
      {
       "cell_index": 54
      }
     ]
    },
    "ff4671db41a542199e892e9339f05354": {
     "views": [
      {
       "cell_index": 75
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
